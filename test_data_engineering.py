#!/usr/bin/env python3
"""
æ¸¬è©¦æ”¹é€²çš„ ML æ•¸æ“šå·¥ç¨‹æµç¨‹
"""

import csv

def test_data_engineering():
    """æ¸¬è©¦æ•¸æ“šå·¥ç¨‹æµç¨‹"""
    print("ğŸ§ª æ¸¬è©¦æ•¸æ“šå·¥ç¨‹æµç¨‹...")
    
    # è®€å–ä¸€äº›æ¨£æœ¬æ•¸æ“š
    csv_file = "merged_shark_ocean_data.csv"
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            sample_rows = []
            
            # å–å‰10è¡Œä½œç‚ºæ¸¬è©¦
            for i, row in enumerate(reader):
                if i >= 10:
                    break
                sample_rows.append(row)
        
        print(f"ğŸ“Š è®€å–äº† {len(sample_rows)} è¡Œæ¸¬è©¦æ•¸æ“š")
        print(f"ğŸ“‹ æ¬„ä½: {list(sample_rows[0].keys())}")
        
        # é¡¯ç¤ºä¸€äº›æ¨£æœ¬æ•¸æ“š
        print("\nğŸ“‹ æ¨£æœ¬æ•¸æ“š:")
        for i, row in enumerate(sample_rows[:3]):
            print(f"ç¬¬ {i+1} è¡Œ:")
            print(f"  æ—¥æœŸ: {row.get('Date')}")
            print(f"  ç¶“ç·¯åº¦: ({row.get('Longitude')}, {row.get('Latitude')})")
            print(f"  SST: {row.get('SST_Value')}")
            print(f"  CHL: {row.get('CHL_Concentration')}")
            print(f"  é¯Šé­šæ¨™ç±¤: {row.get('has_shark')}")
            print()
        
        # æ¸¬è©¦ç‰¹å¾µé¸æ“‡
        selected_features = [
            'Longitude', 'Latitude', 
            'SST_Value', 'SST_Gradient', 
            'CHL_Concentration', 'CHL_Gradient',
            'SSHA_Value', 'SSHA_Gradient',
            'Thermal_Front_Strength', 'Productivity_Index',
            'dist_to_eddy_center_km', 'Daily_Movement_km',
            'Days_To_Env_Data'
        ]
        
        available_features = [f for f in selected_features if f in sample_rows[0].keys()]
        print(f"âœ… å¯ç”¨ç‰¹å¾µ ({len(available_features)}):")
        for feature in available_features:
            print(f"  - {feature}")
        
        missing_features = [f for f in selected_features if f not in sample_rows[0].keys()]
        if missing_features:
            print(f"âš ï¸ ç¼ºå¤±ç‰¹å¾µ ({len(missing_features)}):")
            for feature in missing_features:
                print(f"  - {feature}")
        
        # æ¸¬è©¦æ•¸æ“šé¡å‹
        print(f"\nğŸ” æ•¸æ“šé¡å‹æª¢æŸ¥:")
        sample_row = sample_rows[0]
        for feature in available_features[:5]:  # åªæª¢æŸ¥å‰5å€‹
            value = sample_row.get(feature)
            try:
                float_val = float(value)
                print(f"  {feature}: '{value}' â†’ {float_val} âœ…")
            except:
                print(f"  {feature}: '{value}' â†’ ç„¡æ³•è½‰æ›ç‚ºæ•¸å€¼ âŒ")
        
        # çµ±è¨ˆé¯Šé­šæ¨™ç±¤åˆ†ä½ˆ
        shark_labels = [int(float(row.get('has_shark', 0))) for row in sample_rows]
        shark_count = sum(shark_labels)
        no_shark_count = len(shark_labels) - shark_count
        
        print(f"\nğŸ¦ˆ æ¨™ç±¤åˆ†ä½ˆ:")
        print(f"  æœ‰é¯Šé­š (1): {shark_count}")
        print(f"  æ²’é¯Šé­š (0): {no_shark_count}")
        
        return True
        
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {csv_file}")
        return False
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹æ¸¬è©¦æ•¸æ“šå·¥ç¨‹æµç¨‹...")
    
    success = test_data_engineering()
    
    if success:
        print("\nâœ… æ¸¬è©¦å®Œæˆï¼æ•¸æ“šå·¥ç¨‹æµç¨‹çœ‹èµ·ä¾†æ­£å¸¸ã€‚")
        print("\nğŸ’¡ å»ºè­°:")
        print("  1. ä½¿ç”¨ /api/v1/ml/predict-advanced ç«¯é»é€²è¡Œé æ¸¬")
        print("  2. æŸ¥çœ‹ /api/v1/ml/features ç«¯é»äº†è§£ç‰¹å¾µå·¥ç¨‹ç´°ç¯€")
        print("  3. ä½¿ç”¨ /api/v1/ml/model-info ç«¯é»æª¢æŸ¥æ¨¡å‹ä¿¡æ¯")
    else:
        print("\nâŒ æ¸¬è©¦å¤±æ•—ï¼è«‹æª¢æŸ¥æ•¸æ“šæª”æ¡ˆå’Œè¨­å®šã€‚")

if __name__ == "__main__":
    main()