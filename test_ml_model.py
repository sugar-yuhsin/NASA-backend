#!/usr/bin/env python3
"""
æ¸¬è©¦æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é æ¸¬åŠŸèƒ½
ç›´æ¥ä½¿ç”¨ joblib è¼‰å…¥æ¨¡å‹ä¸¦é€²è¡Œé æ¸¬
"""

import os
import csv
import sys

def test_model_loading():
    """æ¸¬è©¦æ¨¡å‹è¼‰å…¥"""
    model_path = "shark_rf_model_round_18.joblib"
    
    print("ğŸ” æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ...")
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
        return None
    
    print(f"âœ… æ¨¡å‹æª”æ¡ˆå­˜åœ¨: {model_path}")
    print(f"ğŸ“ æª”æ¡ˆå¤§å°: {os.path.getsize(model_path) / (1024 * 1024):.2f} MB")
    
    try:
        import joblib
        print("âœ… joblib å·²å®‰è£")
    except ImportError:
        print("âŒ joblib æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install joblib")
        return None
    
    try:
        model = joblib.load(model_path)
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ: {type(model).__name__}")
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None

def get_model_info(model):
    """ç²å–æ¨¡å‹è©³ç´°ä¿¡æ¯"""
    if model is None:
        return
    
    print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   é¡å‹: {type(model).__name__}")
    
    # å˜—è©¦ç²å–æ¨¡å‹å±¬æ€§
    attrs_to_check = [
        'n_features_in_',
        'feature_names_in_',
        'classes_',
        'n_estimators',
        'max_depth',
        'n_classes_'
    ]
    
    for attr in attrs_to_check:
        if hasattr(model, attr):
            value = getattr(model, attr)
            if hasattr(value, 'tolist'):
                value = value.tolist()
            print(f"   {attr}: {value}")

def create_sample_csv():
    """å‰µå»ºæ¸¬è©¦ç”¨çš„ CSV æª”æ¡ˆ"""
    csv_filename = "test_prediction.csv"
    
    # å‰µå»ºä¸€äº›æ¸¬è©¦æ•¸æ“š
    test_data = [
        ["feature1", "feature2", "feature3", "feature4"],
        [1.0, 2.0, 3.0, 4.0],
        [2.5, 3.5, 4.5, 5.5],
        [0.5, 1.5, 2.5, 3.5],
        [3.0, 4.0, 5.0, 6.0]
    ]
    
    with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerows(test_data)
    
    print(f"âœ… å‰µå»ºæ¸¬è©¦ CSV æª”æ¡ˆ: {csv_filename}")
    return csv_filename

def test_prediction_with_csv(model, csv_filename):
    """æ¸¬è©¦ä½¿ç”¨ CSV æª”æ¡ˆé€²è¡Œé æ¸¬"""
    if model is None:
        return
    
    try:
        import numpy as np
        print("âœ… numpy å·²å®‰è£")
    except ImportError:
        print("âŒ numpy æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install numpy")
        return
    
    print(f"\nğŸ§ª æ¸¬è©¦é æ¸¬ - ä½¿ç”¨ {csv_filename}")
    
    try:
        # è®€å– CSV æª”æ¡ˆ
        data_rows = []
        with open(csv_filename, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            headers = next(reader)  # è·³éæ¨™é¡Œè¡Œ
            
            for row in reader:
                # è½‰æ›ç‚ºæ•¸å€¼
                numeric_row = []
                for value in row:
                    try:
                        numeric_row.append(float(value))
                    except ValueError:
                        numeric_row.append(0.0)
                data_rows.append(numeric_row)
        
        print(f"ğŸ“Š è®€å–æ•¸æ“š: {len(data_rows)} è¡Œ, {len(headers)} åˆ—")
        print(f"ğŸ“‹ æ¬„ä½: {headers}")
        
        if not data_rows:
            print("âŒ æ²’æœ‰æœ‰æ•ˆçš„æ•¸æ“šè¡Œ")
            return
        
        # é€²è¡Œé æ¸¬
        X = np.array(data_rows)
        print(f"ğŸ”¢ æ•¸æ“šå½¢ç‹€: {X.shape}")
        
        predictions = model.predict(X)
        print(f"âœ… é æ¸¬å®Œæˆ!")
        print(f"ğŸ“ˆ é æ¸¬çµæœ: {predictions.tolist()}")
        
        # çµ±è¨ˆä¿¡æ¯
        unique_predictions = np.unique(predictions)
        print(f"ğŸ¯ é æ¸¬ç¨®é¡: {len(unique_predictions)} ç¨®")
        print(f"ğŸ“Š ä¸åŒé æ¸¬å€¼: {unique_predictions.tolist()}")
        
        # å¦‚æœæ¨¡å‹æ”¯æ´é æ¸¬æ©Ÿç‡
        try:
            probabilities = model.predict_proba(X)
            print(f"ğŸ“Š é æ¸¬æ©Ÿç‡å½¢ç‹€: {probabilities.shape}")
            print(f"ğŸ“ˆ ç¬¬ä¸€å€‹æ¨£æœ¬çš„æ©Ÿç‡: {probabilities[0].tolist()}")
        except:
            print("â„¹ï¸  æ¨¡å‹ä¸æ”¯æ´æ©Ÿç‡é æ¸¬")
        
    except Exception as e:
        print(f"âŒ é æ¸¬å¤±æ•—: {e}")

def test_simple_prediction(model):
    """æ¸¬è©¦ç°¡å–®æ•¸æ“šé æ¸¬"""
    if model is None:
        return
    
    try:
        import numpy as np
    except ImportError:
        return
    
    print("\nğŸ§ª æ¸¬è©¦ç°¡å–®é æ¸¬")
    
    try:
        # å‰µå»ºç°¡å–®çš„æ¸¬è©¦æ•¸æ“š
        test_data = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
        predictions = model.predict(test_data)
        
        print(f"âœ… ç°¡å–®é æ¸¬æˆåŠŸ!")
        print(f"ğŸ“Š æ¸¬è©¦æ•¸æ“š: {test_data.tolist()}")
        print(f"ğŸ“ˆ é æ¸¬çµæœ: {predictions.tolist()}")
        
    except Exception as e:
        print(f"âŒ ç°¡å–®é æ¸¬å¤±æ•—: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹æ¸¬è©¦æ©Ÿå™¨å­¸ç¿’æ¨¡å‹...")
    
    # æ¸¬è©¦æ¨¡å‹è¼‰å…¥
    model = test_model_loading()
    
    # ç²å–æ¨¡å‹ä¿¡æ¯
    get_model_info(model)
    
    # å‰µå»ºæ¸¬è©¦ CSV
    csv_filename = create_sample_csv()
    
    # æ¸¬è©¦ CSV é æ¸¬
    test_prediction_with_csv(model, csv_filename)
    
    # æ¸¬è©¦ç°¡å–®é æ¸¬
    test_simple_prediction(model)
    
    print("\nâœ… æ¸¬è©¦å®Œæˆ!")
    
    # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
    if os.path.exists(csv_filename):
        os.remove(csv_filename)
        print(f"ğŸ§¹ æ¸…ç†æ¸¬è©¦æª”æ¡ˆ: {csv_filename}")

if __name__ == "__main__":
    main()