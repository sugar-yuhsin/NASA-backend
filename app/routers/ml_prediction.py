"""
æ©Ÿå™¨å­¸ç¿’é æ¸¬è·¯ç”±
è™•ç† CSV ä¸Šå‚³å’Œ shark_rf_model é æ¸¬
"""

from fastapi import APIRouter, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
import joblib
import pandas as pd
import numpy as np
import io
from typing import Dict, List, Any
import os

router = APIRouter()

# æ¨¡å‹æª”æ¡ˆè·¯å¾‘
MODEL_PATH = "shark_rf_model_round_18.joblib"

# å…¨åŸŸæ¨¡å‹è®Šæ•¸ï¼ˆè¼‰å…¥ä¸€æ¬¡ï¼Œé‡è¤‡ä½¿ç”¨ï¼‰
_model = None

def load_model():
    """è¼‰å…¥ joblib æ¨¡å‹"""
    global _model
    
    if _model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                raise FileNotFoundError(f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {MODEL_PATH}")
            
            _model = joblib.load(MODEL_PATH)
            print(f"âœ… æˆåŠŸè¼‰å…¥æ¨¡å‹: {type(_model)}")
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            raise
    
    return _model

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """æ•¸æ“šé è™•ç†"""
    try:
        # é€™è£¡æ ¹æ“šä½ çš„æ¨¡å‹éœ€æ±‚é€²è¡Œæ•¸æ“šé è™•ç†
        # ä¾‹å¦‚ï¼šè™•ç†ç¼ºå¤±å€¼ã€ç‰¹å¾µé¸æ“‡ã€æ•¸æ“šè½‰æ›ç­‰
        
        # ç§»é™¤éæ•¸å€¼åˆ—ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        df_processed = df[numeric_columns].copy()
        
        # è™•ç†ç¼ºå¤±å€¼
        df_processed = df_processed.fillna(0)
        
        print(f"âœ… æ•¸æ“šé è™•ç†å®Œæˆï¼Œç‰¹å¾µæ•¸: {df_processed.shape[1]}, æ¨£æœ¬æ•¸: {df_processed.shape[0]}")
        
        return df_processed
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šé è™•ç†å¤±æ•—: {e}")
        raise

@router.post("/predict")
async def predict_with_csv(file: UploadFile = File(...)):
    """
    ä¸Šå‚³ CSV æª”æ¡ˆä¸¦ä½¿ç”¨ RF æ¨¡å‹é€²è¡Œé æ¸¬
    
    - **file**: ä¸Šå‚³çš„ CSV æª”æ¡ˆ
    
    è¿”å›é æ¸¬çµæœå’Œç›¸é—œçµ±è¨ˆä¿¡æ¯
    """
    try:
        # é©—è­‰æª”æ¡ˆé¡å‹
        if not file.filename.endswith('.csv'):
            raise HTTPException(
                status_code=400,
                detail="åªæ”¯æ´ CSV æª”æ¡ˆï¼Œè«‹ä¸Šå‚³ .csv æ ¼å¼çš„æª”æ¡ˆ"
            )
        
        # è®€å– CSV æª”æ¡ˆ
        contents = await file.read()
        csv_data = io.StringIO(contents.decode('utf-8'))
        df = pd.read_csv(csv_data)
        
        print(f"ğŸ“ æ”¶åˆ° CSV æª”æ¡ˆ: {file.filename}")
        print(f"ğŸ“Š åŸå§‹æ•¸æ“šå½¢ç‹€: {df.shape}")
        print(f"ğŸ“‹ æ¬„ä½åç¨±: {list(df.columns)}")
        
        # è¼‰å…¥æ¨¡å‹
        model = load_model()
        
        # æ•¸æ“šé è™•ç†
        df_processed = preprocess_data(df)
        
        # é€²è¡Œé æ¸¬
        predictions = model.predict(df_processed)
        
        # å¦‚æœæ¨¡å‹æ”¯æ´ï¼Œä¹Ÿå¯ä»¥ç²å–é æ¸¬æ©Ÿç‡
        try:
            prediction_proba = model.predict_proba(df_processed)
            has_proba = True
        except:
            prediction_proba = None
            has_proba = False
        
        # æº–å‚™è¿”å›çµæœ
        results = {
            "status": "success",
            "file_info": {
                "filename": file.filename,
                "original_rows": len(df),
                "original_columns": len(df.columns),
                "processed_rows": len(df_processed),
                "processed_columns": len(df_processed.columns)
            },
            "model_info": {
                "model_type": str(type(model).__name__),
                "model_path": MODEL_PATH
            },
            "predictions": {
                "values": predictions.tolist(),
                "count": len(predictions),
                "unique_predictions": len(np.unique(predictions))
            }
        }
        
        # å¦‚æœæœ‰é æ¸¬æ©Ÿç‡ï¼ŒåŠ å…¥çµæœ
        if has_proba:
            results["predictions"]["probabilities"] = prediction_proba.tolist()
        
        # æ·»åŠ çµ±è¨ˆä¿¡æ¯
        if len(np.unique(predictions)) <= 10:  # åˆ†é¡å•é¡Œ
            unique, counts = np.unique(predictions, return_counts=True)
            results["predictions"]["distribution"] = dict(zip(unique.tolist(), counts.tolist()))
        else:  # å›æ­¸å•é¡Œ
            results["predictions"]["statistics"] = {
                "mean": float(np.mean(predictions)),
                "std": float(np.std(predictions)),
                "min": float(np.min(predictions)),
                "max": float(np.max(predictions)),
                "median": float(np.median(predictions))
            }
        
        return results
        
    except Exception as e:
        print(f"âŒ é æ¸¬å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"é æ¸¬å¤±æ•—: {str(e)}"
        )

@router.post("/predict-detailed")
async def predict_with_csv_detailed(file: UploadFile = File(...)):
    """
    ä¸Šå‚³ CSV æª”æ¡ˆä¸¦è¿”å›è©³ç´°çš„é æ¸¬çµæœï¼ˆåŒ…å«åŸå§‹æ•¸æ“šï¼‰
    """
    try:
        # é©—è­‰æª”æ¡ˆé¡å‹
        if not file.filename.endswith('.csv'):
            raise HTTPException(
                status_code=400,
                detail="åªæ”¯æ´ CSV æª”æ¡ˆï¼Œè«‹ä¸Šå‚³ .csv æ ¼å¼çš„æª”æ¡ˆ"
            )
        
        # è®€å– CSV æª”æ¡ˆ
        contents = await file.read()
        csv_data = io.StringIO(contents.decode('utf-8'))
        df = pd.read_csv(csv_data)
        
        # è¼‰å…¥æ¨¡å‹ä¸¦é æ¸¬
        model = load_model()
        df_processed = preprocess_data(df)
        predictions = model.predict(df_processed)
        
        # å°‡é æ¸¬çµæœåŠ åˆ°åŸå§‹æ•¸æ“šä¸­
        df_result = df.copy()
        df_result['prediction'] = predictions
        
        # å˜—è©¦ç²å–é æ¸¬æ©Ÿç‡
        try:
            prediction_proba = model.predict_proba(df_processed)
            # å¦‚æœæ˜¯äºŒåˆ†é¡ï¼Œæ·»åŠ æ©Ÿç‡
            if prediction_proba.shape[1] == 2:
                df_result['probability_class_0'] = prediction_proba[:, 0]
                df_result['probability_class_1'] = prediction_proba[:, 1]
            else:
                # å¤šåˆ†é¡ï¼Œæ·»åŠ æ¯å€‹é¡åˆ¥çš„æ©Ÿç‡
                for i in range(prediction_proba.shape[1]):
                    df_result[f'probability_class_{i}'] = prediction_proba[:, i]
        except:
            pass
        
        # è½‰æ›ç‚ºå­—å…¸æ ¼å¼è¿”å›
        result_data = df_result.to_dict('records')
        
        return {
            "status": "success",
            "file_info": {
                "filename": file.filename,
                "total_rows": len(df_result)
            },
            "data": result_data
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è©³ç´°é æ¸¬å¤±æ•—: {str(e)}"
        )

@router.get("/model-info")
async def get_model_info():
    """ç²å–æ¨¡å‹ä¿¡æ¯"""
    try:
        model = load_model()
        
        info = {
            "model_type": str(type(model).__name__),
            "model_path": MODEL_PATH,
            "file_exists": os.path.exists(MODEL_PATH),
            "file_size_mb": round(os.path.getsize(MODEL_PATH) / (1024 * 1024), 2) if os.path.exists(MODEL_PATH) else 0
        }
        
        # å˜—è©¦ç²å–æ¨¡å‹çš„é¡å¤–ä¿¡æ¯
        try:
            if hasattr(model, 'n_features_in_'):
                info['n_features'] = model.n_features_in_
            if hasattr(model, 'feature_names_in_'):
                info['feature_names'] = model.feature_names_in_.tolist()
            if hasattr(model, 'classes_'):
                info['classes'] = model.classes_.tolist()
            if hasattr(model, 'n_estimators'):
                info['n_estimators'] = model.n_estimators
        except:
            pass
        
        return info
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ç²å–æ¨¡å‹ä¿¡æ¯å¤±æ•—: {str(e)}"
        )

@router.post("/reload-model")
async def reload_model():
    """é‡æ–°è¼‰å…¥æ¨¡å‹"""
    global _model
    try:
        _model = None  # æ¸…é™¤å¿«å–
        model = load_model()
        
        return {
            "status": "success",
            "message": "æ¨¡å‹é‡æ–°è¼‰å…¥æˆåŠŸ",
            "model_type": str(type(model).__name__)
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"é‡æ–°è¼‰å…¥æ¨¡å‹å¤±æ•—: {str(e)}"
        )